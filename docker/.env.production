# Personal AI Assistant - Production Environment Configuration
# Copy to .env and fill in secrets

# =============================================================================
# API AUTHENTICATION
# =============================================================================
# Generate with: python3 -c "import uuid; print(uuid.uuid4())"
API_KEY=your-secure-uuid-here

# =============================================================================
# AI BACKENDS (Phase 2B)
# =============================================================================
# Claude API Key (Primary AI Backend)
# Get from: https://console.anthropic.com/
ANTHROPIC_API_KEY=sk-ant-your-key-here

# Available backends (comma-separated)
AVAILABLE_BACKENDS=claude,mock

# Backend selection
PRIMARY_BACKEND=claude
SECONDARY_BACKEND=mock
BACKEND_SELECTION_STRATEGY=sequential

# Ollama Configuration (Optional - for local AI fallback)
# AVAILABLE_BACKENDS=claude,ollama,mock
# OLLAMA_BASE_URL=http://192.168.7.187:11434
# OLLAMA_MODEL=llama3.2:latest

# =============================================================================
# APPLICATION SETTINGS
# =============================================================================
DEBUG=false
LOG_LEVEL=INFO
HOST=0.0.0.0
PORT=8000

# =============================================================================
# NOTES
# =============================================================================
# Phase 2B Features:
# - Pluggable AI backends (Claude, Ollama, Mock)
# - Automatic fallback if primary fails
# - Backend performance metrics
# - /consciousness-check-v2 endpoint with backend selection
#
# Security:
# - API_KEY should be a UUID (128-bit entropy)
# - ANTHROPIC_API_KEY is your Claude API key (starts with sk-ant-)
# - Store secrets in 1Password or password manager
# - Never commit .env files to git
#
# Costs (typical personal use):
# - Claude API: $0.01-0.10/day
# - Ollama: Free (local inference)
# - Mock: Free (testing only)
